{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ML y modelos predictivos\n",
    "\n",
    "### Finanzas Cuantitativas y Ciencia de Datos\n",
    "#### Rodrigo Lugo Frias y Le√≥n Berdichevsky Acosta\n",
    "#### ITAM Primavera 2019\n",
    "\n",
    "_INSTRUCCIONES:_\n",
    "* Todas las celdas se corren haciendo __Shift + Enter__ o __Ctrl + Enter__\n",
    "\n",
    "_NOTAS:_\n",
    "* _Notebook adaptado de distintas fuentes y proyectos personales_\n",
    "___\n",
    "\n",
    "## Contenido\n",
    "\n",
    "1. __Preparar la data__\n",
    "2. __Moving average__\n",
    "3. __Exponential Moving average__\n",
    "4. __Regresion Lineal__\n",
    "5. __k Nearest Neighbors__\n",
    "6. __ARIMA__\n",
    "7. __Long Short Term Memory__\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import utils.frontera_eficiente\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "import datetime as dt\n",
    "# Inline command for matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "#Silence all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocks = 'data/ALSEA MM Equity.csv'\n",
    "alsea  = pd.read_csv(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsea.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alsea.Open.tail(50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date( df ):\n",
    "    df.Date = df.Date.apply(lambda x : pd.to_datetime(str(x), format = \"%Y%m%d\"))\n",
    "    df.set_index(df.Date, inplace = True)\n",
    "    df = df.copy()[df.columns[1:]]\n",
    "    return df\n",
    "\n",
    "alsea = change_date(alsea)\n",
    "\n",
    "# Tomamos una muestra de los datos (Los primeros 12 anios)\n",
    "df = alsea.head(3000)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Open.tail(50).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "ax.set_title('Alsea')\n",
    "df['Last'].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_data = df.copy()[['Last']].reset_index()\n",
    "play_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting data into train and validation\n",
    "\n",
    "train_size = 2./3.\n",
    "\n",
    "df_train = play_data[:int(len(play_data)*train_size)]\n",
    "df_valid = play_data[int(len(play_data)*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_data.shape, df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Training dates: {0} - {1}'.format(df_train['Date'].min(), df_train['Date'].max()))\n",
    "print ('Validation dates: {0} - {1}'.format(df_valid['Date'].min(), df_valid['Date'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(0,1000):\n",
    "    #print(preds,len(df_train)-1000+i,df_train['Last'][len(df_train)-1000+i:].sum())\n",
    "    a = df_train['Last'][len(df_train)-1000+i:].sum() + sum(preds)\n",
    "    b = a/1000\n",
    "    preds.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(df_valid['Last'])-preds),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.sqrt(mean_squared_error(df_valid['Last'].tolist(),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "df_valid['Predictions'] = 0.\n",
    "df_valid['Predictions'] = preds\n",
    "plt.plot(df_train['Last'])\n",
    "plt.plot(df_valid[['Last', 'Predictions']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_preds_ = df_train.Last.ewm(com=0.25).mean().tail(1000).tolist()\n",
    "df_valid['_Predictions_'] = 0\n",
    "df_valid['_Predictions_'] = _preds_\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "plt.plot(df_train['Last'])\n",
    "plt.plot(df_valid[['Last', '_Predictions_']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((np.array(df_valid['Last'])-_preds_),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(df_valid['Last'].tolist(),_preds_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.frontera_eficiente import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kk = pd.read_csv('data/ALSEA MM Equity.csv')\n",
    "kk.columns = ['Date', 'DOpen', 'DHigh', 'DLow', 'DClose', 'Volume', 'PE']\n",
    "kk.to_csv('data/alsea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "#---------------------------------------#\n",
    "# getData \t\t\t\t\t\t\t    #\n",
    "#---------------------------------------#\n",
    "#########################################\n",
    "class getData:\n",
    "\tdef __init__( self, file ):\n",
    "\t\tself.file = file\n",
    "\t\t# ----- #\n",
    "\t\tdf = pd.read_csv(self.file, index_col = 0)\n",
    "\t\tdf = self.index_to_datetime(df)\n",
    "\t\tself.n = 22 # Days to ATR\n",
    "\t\t# ----- #\n",
    "\t\tself.timeseries = df\n",
    "\t\tself.truerange  = self.truerange()\n",
    "\t\tself.atr \t    = self.atr()\n",
    "\t\tself.atr_return = self.atr_return()\n",
    "\t\tself.cum_sum    = self.cum_sum()\n",
    "\t\tself.dataframe\t= self.dataframe()\n",
    "\n",
    "\tdef index_to_datetime( self, df ):\n",
    "\t\t#df.index = df.index.astype('str')\n",
    "\t\t#df.index = df.index.to_datetime()\n",
    "\t\treturn change_date(df)\n",
    "\n",
    "\tdef truerange( self ):\n",
    "\t\tadf = self.timeseries\n",
    "\t\ts1 = pd.Series(np.abs(adf.DHigh - adf.DLow))\n",
    "\t\ts2 = pd.Series(np.abs(adf.DHigh - adf.DClose.shift()))\n",
    "\t\ts3 = pd.Series(np.abs(adf.DLow  - adf.DClose.shift()))\n",
    "\t\tTR = pd.Series(pd.concat([s1,s2,s3],axis=1).max(axis=1), name = 'TrueRange')\n",
    "\t\treturn TR\n",
    "\n",
    "\tdef atr( self ):\n",
    "\t\tn = self.n\n",
    "\t\tTR = self.truerange\n",
    "\t\tATR = pd.Series(pd.ewma(TR, span = n, min_periods = n), name = 'ATR_{}'.format(n))\n",
    "\t\treturn ATR\n",
    "\n",
    "\tdef atr_return( self ):\n",
    "\t\ttday    = self.timeseries.DClose\n",
    "\t\tyday    = self.timeseries.DClose.shift()\n",
    "\t\tatryday = self.atr.shift()\n",
    "\t\tatr_ret = (tday - yday) / atryday\n",
    "\t\tatr_ret = atr_ret.rename('ATR_RET')\n",
    "\t\treturn atr_ret\n",
    "\n",
    "\tdef cum_sum( self ):\n",
    "\t\tatr_ret = self.atr_return\n",
    "\t\tcum_sum = atr_ret.cumsum(axis = 0)\n",
    "\t\tcum_sum = cum_sum.rename('PATR')\n",
    "\t\treturn cum_sum\n",
    "\n",
    "\tdef dataframe( self ):\n",
    "\t\tcols =  ['DOpen', 'DHigh', 'DLow', 'DClose', 'TrueRange', 'ATR_{}'.format(22)]\n",
    "\t\tcols += ['ATR_RET', 'PATR']\n",
    "\t\tadf = self.timeseries.join([self.truerange,self.atr,self.atr_return,self.cum_sum])\n",
    "\t\tadf = adf[cols]\n",
    "\t\treturn adf\n",
    "\n",
    "\tdef plot( self, Series, *args):\n",
    "\t\tfig, ax = plt.subplots(1,figsize=(10, 7))\n",
    "\t\tser = self.dataframe[Series]\n",
    "\t\tser.plot()\n",
    "\t\tplt.xlabel('Year')\n",
    "\t\tplt.ylabel(Series)\n",
    "\t\tif len(args) != 0:\n",
    "\t\t\tplt.title(args[0])\n",
    "\t\tplt.show()\n",
    "#########################################\n",
    "# END: getData  \t\t\t\t\t\t#\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = getData('data/alsea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.dataframe.PATR[23:3023]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ = pd.DataFrame(df.copy()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = 2./3.\n",
    "\n",
    "df_train = df_[:int(len(play_data)*train_size)]\n",
    "df_valid = df_[int(len(play_data)*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(0,1000):\n",
    "    #print(preds,len(df_train)-1000+i,df_train['Last'][len(df_train)-1000+i:].sum())\n",
    "    a = df_train['PATR'][len(df_train)-1000+i:].sum() + sum(preds)\n",
    "    b = a/1000\n",
    "    preds.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(df_valid['PATR'].tolist(),preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "df_valid['Predictions'] = 0.\n",
    "df_valid['Predictions'] = preds\n",
    "plt.plot(df_train['PATR'])\n",
    "plt.plot(df_valid[['PATR', 'Predictions']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_preds_ = df_train.PATR.ewm(com=0.25).mean().tail(1000).tolist()\n",
    "df_valid['_Predictions_'] = 0\n",
    "df_valid['_Predictions_'] = _preds_\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "plt.plot(df_train['PATR'])\n",
    "plt.plot(df_valid[['PATR', '_Predictions_']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(df_valid['PATR'].tolist(),_preds_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMA: different rolling windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_windows = [1,30,90]\n",
    "for win in roll_windows:\n",
    "    _preds_ = df_train.PATR.rolling(win).mean().tail(1000).tolist()\n",
    "    df_valid['roll_window_{0}'.format(win)] = 0\n",
    "    df_valid['roll_window_{0}'.format(win)] = _preds_\n",
    "    error_ = np.sqrt(mean_squared_error(df_valid['PATR'].tolist(),_preds_))\n",
    "    print('RMS = {0}'.format(error_))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "plt.plot(df_train['PATR'])\n",
    "df_valid[df_valid.columns[1:]].plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.copy()\n",
    "df['_index_'] = df.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Initialise and fit linear regression model using `statsmodels`\n",
    "model = smf.ols('PATR ~ _index_', data = df )\n",
    "model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_preds_ = model.predict()\n",
    "\n",
    "print(len(_preds_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "plt.plot(df_train['PATR'])\n",
    "plt.plot(_preds_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jugando con el data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dd.dataframe[1700:1850].copy().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "x.DClose.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils.frontera_eficiente import RegressionML\n",
    "\n",
    "reg = RegressionML(x.DClose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.Results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.Plot('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = dd.dataframe[1850:1851].copy().reset_index()\n",
    "x_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_predict = np.array(150)\n",
    "pred       = reg.model.predict(to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Valor t+1\\n\\tReal:\\t{0}\\n\\tPred:\\t{1}'.format(x_.DClose.iloc[0],pred[0]))\n",
    "print('\\tRMS:\\t{0}'.format(np.sqrt(mean_squared_error(x_.DClose.tolist(),pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More than one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf = dd.dataframe.copy()[23:3023]\n",
    "df_mf = df_mf[['DOpen', 'DHigh', 'DLow', 'DClose','PATR']]\n",
    "df_mf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mf_train = df_mf[:int(len(play_data)*train_size)]\n",
    "df_mf_valid = df_mf[int(len(play_data)*train_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Build linear regression model to get DClose price\n",
    "# Split data into predictors X and output Y\n",
    "predictors = ['DLow','DHigh','DOpen']\n",
    "X = df_mf_train[predictors]\n",
    "y = df_mf_train['DClose']\n",
    "\n",
    "# Initialise and fit model\n",
    "lm    = LinearRegression()\n",
    "model = lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mf_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'alpha = {model.intercept_}')\n",
    "print(f'betas = {model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_preds_ = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "plt.plot(df_mf_train['DClose'].tolist())\n",
    "plt.plot(_preds_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = df_mf_valid[predictors]\n",
    "_preds_valid = model.predict(X_new)\n",
    "\n",
    "df_mf_valid['pred'] = _preds_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "plt.plot(df_mf_train['DClose'])\n",
    "plt.plot(df_mf_valid.DClose)\n",
    "plt.plot(df_mf_valid.pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresion Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dd.dataframe[2700:2950].copy().reset_index() \n",
    "x.DClose.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = x.DClose.diff()\n",
    "rets.plot.density()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "func_log = 1./(1+np.exp(-rets))\n",
    "x['Log'] = func_log\n",
    "x.Log.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# New library for techinical indicators\n",
    "import talib as ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.dataframe[50:3050].copy()[['DOpen','DHigh','DLow','DClose','ATR_22']]\n",
    "df['S_10'] = df['DClose'].rolling(window=10).mean()\n",
    "df['Open-Close'] = df['DOpen'] - df['DClose'].shift(1)\n",
    "df['Open-Open']  = df['DOpen'] - df['DOpen'].shift(1)\n",
    "# Relative Strength Index\n",
    "df['RSI'] = ta.RSI(np.array(df['DClose']), timeperiod =10)\n",
    "df.RSI.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df[df==np.inf]=np.nan\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.reset_index()\n",
    "X = X.iloc[:,1:10].fillna(method='pad')\n",
    "X.iloc[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target\n",
    "y = np.where (X['DClose'].shift(-1) > X['DClose'],1,-1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "split = 250\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "logmodel = LogisticRegression()\n",
    "logmodel = logmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(zip(X.columns, np.transpose(logmodel.coef_)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "probability = logmodel.predict_proba(X_test)\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pd.DataFrame(probability,columns=['PVenta','PCompra'])\n",
    "probs['Close'] = X_test.DClose.reset_index(drop=True).values\n",
    "probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted  = logmodel.predict(X_test)\n",
    "resultados = probs.copy()\n",
    "resultados['Prediccion'] = predicted\n",
    "resultados['Real']       = y_test\n",
    "resultados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion del modelo\n",
    "\n",
    "conf_mat = pd.DataFrame(metrics.confusion_matrix(y_test, predicted),\n",
    "            columns=['Pred: VENTA','Pred: COMPRA'])\n",
    "conf_mat['ind'] = ['Real: VENTA','Real: COMPRA']\n",
    "conf_mat.set_index('ind')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test, predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = metrics.confusion_matrix(y_test, predicted)\n",
    "\n",
    "x.trace()\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (logmodel.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y == -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logmodel = LogisticRegression()\n",
    "\n",
    "def accuracy( matrix ):\n",
    "    return x.trace()/x.sum()\n",
    "\n",
    "def explorar_hiperparametros( df, roll_win, split):\n",
    "    df['S_10'] = df['DClose'].rolling(window=roll_win).mean()\n",
    "    df['Open-Close'] = df['DOpen'] - df['DClose'].shift(1)\n",
    "    df['Open-Open']  = df['DOpen'] - df['DOpen'].shift(1)\n",
    "    # Relative Strength Index\n",
    "    df['RSI'] = ta.RSI(np.array(df['DClose']), timeperiod =10)\n",
    "    df = df.dropna()\n",
    "    df[df==np.inf]=np.nan\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    # Determinar observables\n",
    "    X = df.reset_index()\n",
    "    X = X.iloc[:,1:10].fillna(method='pad')\n",
    "    # TTSplit\n",
    "    X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]\n",
    "    # Entrenar modelo\n",
    "    logmodel = LogisticRegression()\n",
    "    logmodel = logmodel.fit(X_train,y_train)\n",
    "    # Crear predicciones\n",
    "    predicted  = logmodel.predict(X_test)\n",
    "    # Confussion matrix\n",
    "    mat_conf = metrics.confusion_matrix(y_test, predicted)\n",
    "    \n",
    "    return accuracy(mat_conf)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.dataframe[50:3050].copy()[['DOpen','DHigh','DLow','DClose','ATR_22']]\n",
    "explorar_hiperparametros(df, 20, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_windows = range(0,50,10)\n",
    "splits       = range(500,2500,100)\n",
    "\n",
    "accs = []\n",
    "for roll in roll_windows:\n",
    "    for splt in splits:\n",
    "        acc = explorar_hiperparametros(df, roll, splt)\n",
    "        accs.append([roll,splt,acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = pd.DataFrame(accs)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap( data=hm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
