{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "_Francisco José Álvarez Rojo_\n",
    "\n",
    "_Jorge III Altamirano Astorga - 175904_\n",
    "\n",
    "_Paulina Gómez Mont Wickers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs4\n",
    "import requests\n",
    "import sys\n",
    "from dateutil import parser #esta lib es más útil que la de Python para interpretar fechas parciales, como las de Twitter\n",
    "import re\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from nltk.sentiment import SentimentAnalyzer\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los Datos\n",
    "\n",
    "### Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos los tweets a un Pandas Dataframe con el fin poder manipular mejor la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaa6766/.local/lib/python3.6/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source            object\n",
       "time      datetime64[ns]\n",
       "tweet             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmv = pd.read_csv(\"tweets.full/elfinanciero_mx.2014.csv\", sep=\"|\") \n",
    "for i in range(2015,2020):\n",
    "    bmv = bmv.append(pd.read_csv(\"tweets.full/elfinanciero_mx.%d.csv\"%i, sep=\"|\")) \n",
    "bmv[\"source\"] = \"elfinanciero_mx\"\n",
    "for i in range(2014,2020):\n",
    "    bmv = bmv.append(pd.read_csv(\"tweets.full/eleconomista.%d.csv\"%i, sep=\"|\")) \n",
    "bmv[\"source\"] = np.where(pd.isna(bmv[\"source\"]), \"eleconomista\", bmv.source)\n",
    "for i in range(2014,2020):\n",
    "    bmv = bmv.append(pd.read_csv(\"tweets.full/eluniversal.%d.csv\"%i, sep=\"|\")) \n",
    "bmv[\"source\"] = np.where(pd.isna(bmv[\"source\"]), \"eluniversal\", bmv.source)\n",
    "bmv.time = pd.to_datetime(bmv.time)\n",
    "bmv.tweet = bmv.tweet.astype(\"str\")\n",
    "bmv.source = bmv.source.astype(\"str\")\n",
    "bmv = bmv.drop(columns=[\"page\"])\n",
    "bmv.to_csv(\"tweets.csv.xz\", compression=\"xz\")\n",
    "bmv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26948</td>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Se acaba el año, por eso conoce la noticias má...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26946</td>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Times Square congregá a 1 millón de personas p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26947</td>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>#PORSINOLOVISTE @inah_mx halló cráneos de tzom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       source                time  \\\n",
       "0       26948  eluniversal 2013-12-31 20:14:00   \n",
       "1       26946  eluniversal 2013-12-31 20:14:00   \n",
       "2       26947  eluniversal 2013-12-31 20:14:00   \n",
       "\n",
       "                                               tweet  \n",
       "0  Se acaba el año, por eso conoce la noticias má...  \n",
       "1  Times Square congregá a 1 millón de personas p...  \n",
       "2  #PORSINOLOVISTE @inah_mx halló cráneos de tzom...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    del(bmv) #borrar variable, para no ocupar memoria\n",
    "except:\n",
    "    ;\n",
    "tweets = pd.read_csv(\"tweets.csv.xz\", compression=\"xz\")\n",
    "tweets.time = pd.to_datetime(tweets.time)\n",
    "#ordenar columnas \n",
    "tweets = tweets.sort_values(by=[\"time\"])\n",
    "#remover tweets con fechas a futuro (error de interpretación de fechas)\n",
    "tweets = tweets[tweets.time < datetime.date.today().isoformat()] \n",
    "#reindizar\n",
    "tweets.index = range(0, tweets.shape[0])\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356058, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date         close       volume  deltaPct  sentiment\n",
      "0 2013-12-26  42540.320313  139436700.0  0.000000        0.0\n",
      "1 2013-12-27  42753.218750  154856000.0  0.497971        0.0\n",
      "2 2013-12-30  42958.820313  175830000.0  0.478602        0.0\n",
      "3 2014-01-02  42188.449219  139707400.0 -1.826024       -1.0\n",
      "4 2014-01-03  42064.968750  141022700.0 -0.293547        0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "date         datetime64[ns]\n",
       "close               float64\n",
       "volume              float64\n",
       "deltaPct            float64\n",
       "sentiment           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipc = pd.read_csv(\"bmv_ipc.csv\", sep=',')\n",
    "ipc.Date = pd.to_datetime(ipc.Date)\n",
    "#quitamos columnas menos relevantes para nuestro análisis\n",
    "ipc = ipc.drop([\"Open\", \"High\", \"Low\", \"Close\"], axis=1)\n",
    "#quito espacios\n",
    "ipc = ipc.rename({\"Adj Close\": \"close\", \"Volume\": \"volume\", \"Date\": \"date\"}, axis=\"columns\")\n",
    "#sacamos la diferencia porcentual del cierre del día anterior\n",
    "ipc[\"deltaPct\"] = 100 * (1 - ipc[\"close\"].shift(1) / ipc[\"close\"])\n",
    "#asignamos un sentimiento basado en el cambio\n",
    "ipc.loc[ipc.deltaPct <= -0.5, \"sentiment\"] = -1 #sentimiento negativo\n",
    "ipc.loc[ipc.deltaPct >= +0.5, \"sentiment\"] = 1 #sentimiento positivo\n",
    "ipc.loc[ipc.sentiment.isna(), \"sentiment\"] = 0 #sentimiento neutral\n",
    "#en caso de no existir sentimiento lo ponemos neutral\n",
    "ipc.loc[ipc.deltaPct.isna(), \"deltaPct\"] = 0\n",
    "print(ipc.head())\n",
    "ipc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-12-26 00:00:00 2019-05-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(ipc.date.min(), ipc.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-12-31 20:14:00 2019-05-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(tweets.time.min(), tweets.time.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('spanish')\n",
    "stemmer = nltk.stem.SnowballStemmer('spanish')\n",
    "non_words = list(punctuation)\n",
    "non_words.extend(['¿', '¡'])\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "def tokenize(text):\n",
    "    text = ''.join([c for c in text if c not in non_words])\n",
    "    tokens = word_tokenize(text)\n",
    "    # stem\n",
    "    try:\n",
    "        stems = stem_tokens(tokens, stemmer)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(text)\n",
    "        stems = ['']\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De manera experimental realizaremos un entrenamiento con el sentimiento que obtuvimos en el paso anterior (IPC), y lo asignaremos a los valores de la misma fecha del tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ipc</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Se acaba el año, por eso conoce la noticias má...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Times Square congregá a 1 millón de personas p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>#PORSINOLOVISTE @inah_mx halló cráneos de tzom...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>#FOTOGALERÍA  Hallan cráneos en Línea 12 del M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>De Blasio jura mañana como nuevo alcalde de Nu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>#ENTÉRATE Hospitalizan a ex primera dama de #E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>#FOTO Miles de personas esperan el 2014 en Tim...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Desmontan estatua de Stalin en su Georgia nata...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Gentleman de Psy, el video más visto de 2013 e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>Reportan en Tlaxcala dos muertos por influenza...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                time  \\\n",
       "0  eluniversal 2013-12-31 20:14:00   \n",
       "1  eluniversal 2013-12-31 20:14:00   \n",
       "2  eluniversal 2013-12-31 20:14:00   \n",
       "3  eluniversal 2013-12-31 20:14:00   \n",
       "4  eluniversal 2013-12-31 20:14:00   \n",
       "5  eluniversal 2013-12-31 20:14:00   \n",
       "6  eluniversal 2013-12-31 20:14:00   \n",
       "7  eluniversal 2013-12-31 20:14:00   \n",
       "8  eluniversal 2013-12-31 20:14:00   \n",
       "9  eluniversal 2013-12-31 20:14:00   \n",
       "\n",
       "                                               tweet  ipc  sentiment  \n",
       "0  Se acaba el año, por eso conoce la noticias má...  NaN        NaN  \n",
       "1  Times Square congregá a 1 millón de personas p...  NaN        NaN  \n",
       "2  #PORSINOLOVISTE @inah_mx halló cráneos de tzom...  NaN        NaN  \n",
       "3  #FOTOGALERÍA  Hallan cráneos en Línea 12 del M...  NaN        NaN  \n",
       "4  De Blasio jura mañana como nuevo alcalde de Nu...  NaN        NaN  \n",
       "5  #ENTÉRATE Hospitalizan a ex primera dama de #E...  NaN        NaN  \n",
       "6  #FOTO Miles de personas esperan el 2014 en Tim...  NaN        NaN  \n",
       "7  Desmontan estatua de Stalin en su Georgia nata...  NaN        NaN  \n",
       "8  Gentleman de Psy, el video más visto de 2013 e...  NaN        NaN  \n",
       "9  Reportan en Tlaxcala dos muertos por influenza...  NaN        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.drop(columns=[\"sentiment\"], inplace=True, errors=\"ignore\")\n",
    "#sentimiento basado en el porcentaje de cambio del ipc\n",
    "tweets[\"ipc\"] = tweets.join(ipc.set_index(\"date\"), on=\"time\", how=\"left\").deltaPct.round(0)\n",
    "#sentimiento basado en reglas\n",
    "tweets[\"sentiment\"] = tweets.join(ipc.set_index(\"date\"), on=\"time\", how=\"left\").sentiment\n",
    "tweets.drop(tweets.filter(regex=\"Unnamed\"), axis=1, inplace=True) #remover índice incorrecto\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen fechas en las cuales no opera la bolsa, pero sí existen tweets publicados; por lo que es conveniente aplicar dicho tweet al cierre de la jornada del siguiente día hábil para la bolsa. Se puede observar en la salida anterior, el caso de un 1 de Enero, donde la bolsa no laboró. Pero el 2 de enero sí, entonces, dicho tweet aplica para el 2 de Enero. \n",
    "\n",
    "Lo mismo aplica para tweets que son publicados en Sábado o Domingo, por lo que aplicamos el sentimiento del siguiente día hábil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ipc</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                time tweet  ipc  sentiment\n",
       "0  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "1  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "2  eluniversal 2013-12-31 20:14:00     0  0.0        0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tweet_adjust_df(df, columns=[\"sentiment\", \"ipc\"], ipc=ipc[[\"date\", \"sentiment\", \"deltaPct\"]]):\n",
    "    \"\"\"Ajusta el dataframe de tweets con los sentimientos y valor IPC del siguiente día hábil.\n",
    "    Ojo: el dataframe del IPC deberá conteneter (en orden):\n",
    "    * fecha: es con lo que hacemos el índice\n",
    "    * los siguientes valores que coincidan con el parámetro `columns`\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    ipc = ipc.copy()\n",
    "    i = 0\n",
    "    for col in columns:\n",
    "        for (idx, row) in df.loc[df[col].isna(), :].iterrows():\n",
    "            #buscar en las siguientes fechas hábiles, 4 días máx\n",
    "            dates = [df.loc[idx, \"time\"] + datetime.timedelta(days=j) for j in range (0,6)]\n",
    "            dates = ['{0:%Y-%m-%d}'.format(datum) for datum in dates]\n",
    "            ipc_dates = ipc.loc[ipc.date.isin(dates), ipc.keys()[i+1]].head(1)\n",
    "        i += 1\n",
    "    #establecer en sentimiento neutral (0) los que aún así no pudimos determinar el sentimiento\n",
    "    df.loc[np.any(df.isna(), axis=1), np.any(df.isna(), axis=0)] = 0\n",
    "    return df\n",
    "tweets = tweet_adjust_df(tweets, [\"ipc\", \"sentiment\"]).copy()\n",
    "# tweets = tweets.drop(columns=[\"Unnamed: 0\"])\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america movil', 'AMX', 'banco de mexico']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['america movil','AMX','banco de mexico','banxico', 'mexico', 'bmv', \n",
    "            'bolsa mexicana de valores', 'ipc', 'walmex','femsa','kof',\n",
    "            'televisa', 'TLEVISA', 'grupo mexico', 'gmexico', 'banorte','GFNORTEO',\n",
    "            'cemex','alfa', 'peñoles', 'pe&oles', 'inbursa', \"DINBUR1A\",\n",
    "            'elektra', 'mexichem', 'MEXCHEM', 'bimbo', 'arca continental', 'ac',\n",
    "            'kimberly-clark', \"KIMBERA\", 'genomma lab', 'labb',\n",
    "            'puerto de liverpool', 'LIVEPOLC', 'grupo aeroportuario', \"ASURB\", \n",
    "            \"omab\", 'alpek', 'ica', 'tv azteca', 'AZTECA',\n",
    "            'ohl', 'maseca', 'GRUMA', 'alsea', 'carso', 'lala', 'banregio',\n",
    "            'ienova', 'pinfra', 'santander mexico', 'presidente de mexico', \"BSMXB\", \n",
    "            'cetes', 'tasa']\n",
    "keywords[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet</th>\n",
       "      <th>ipc</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eluniversal</td>\n",
       "      <td>2013-12-31 20:14:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source                time tweet  ipc  sentiment\n",
       "0  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "1  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "2  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "3  eluniversal 2013-12-31 20:14:00     0  0.0        0.0\n",
       "4  eluniversal 2013-12-31 20:14:00     0  0.0        0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot index with vector containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a3a8cc758b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2917\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2918\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot index with vector containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "tweets[tweets.tweet.str.contains(\"0\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
