{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final\n",
    "\n",
    "_Jorge III Altamirano Astorga - 175904_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs4\n",
    "import requests\n",
    "import sys\n",
    "from dateutil import parser #esta lib es más útil que la de Python para interpretar fechas parciales, como las de Twitter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&src=typd&lang=en'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWSPPR=\"elfinanciero_mx\"\n",
    "STOCK=\"bimbo\"\n",
    "YEAR=\"2018\"\n",
    "q = 'https://mobile.twitter.com/search?q=' + STOCK + \\\n",
    "      '%20from%3A' + NEWSPPR + \\\n",
    "      '%20since%3A'+YEAR+'-01-01%20until%3A'+YEAR+'-12-31&src=typd&lang=en'\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(soup, file, i):\n",
    "    tweets = soup.find_all(\"table\", attrs={\"class\": \"tweet\"})\n",
    "    # soup.find_all(\"div\", attrs={\"class\": \"tweet-text\"})\n",
    "    # tweet = tweets[0]\n",
    "    for tweet in tweets:\n",
    "        tweet_text = tweet.find_all('div', attrs={'class': 'tweet-text'})\n",
    "        tweet_date = tweet.find_all(\"td\", attrs={'class': 'timestamp'})\n",
    "        for text in tweet_text:\n",
    "            if type(text) == bs4.element.Tag:\n",
    "                file.write(text.text.strip() + \"|\")\n",
    "        for date in tweet_date:\n",
    "            if type(date) == bs4.element.Tag:\n",
    "                date = date.text.strip() \n",
    "                date = re.sub(YEAR[-2:] + \"$\", \"\", date)\n",
    "                file.write(str(parser.parse(date + \" \" + YEAR) )  + \"|%s\"%i + \"\\n\")\n",
    "# extract_tweets(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop 0 in URL https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&src=typd&lang=en\n",
      "Loop 1 in URL https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&next_cursor=thGAVUV0VFVBYBFoDAo5XGk62-HRIYtAESY8LrAAAB9D-AYk3S8an8AAAAFA2p3HiSFcAADc3WzaOWAAEOf_pdsVegAQ5VfeZv1MAADV4AU0sWAAAOEfeZIRRgAQ1PjSiIV9ACDi39P5VXgAIN1nfqetfQAA22VF7J1dADDg0EXbYWsAEOvlpOMVRwAA5WKXYiF7AADhJiB9eXUAAOUlEMXNegAQ5dvVWV19AADlKU435U8AAOUtQ7olewAQ5Xvq71FtAADWrSaLDWsAAVAhUAFQAlAAA%3D\n",
      "Loop 2 in URL https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&next_cursor=thGAVUV0VFVBaEwLXRuPemuhoWgMCjlcaTrb4dEhi0ARJjwusAAAH0P4BiTdLxqfwAAAAUDanceJIVwAANzdbNo5YAAQ22VF7J1dADDV4AU0sWAAAOVX3mb9TAAA1PjSiIV9ACDhH3mSEUYAEN1nfqetfQAA5_-l2xV6ABDi39P5VXgAIODQRdthawAQ5SUQxc16ABDhJiB9eXUAAOvlpOMVRwAA5WKXYiF7AADWrSaLDWsAAOUpTjflTwAA5S1DuiV7ABDle-rvUW0AAOXb1VldfQABUCFQAVAiUAAA%3D%3D\n",
      "Loop 3 in URL https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&next_cursor=thGAVUV0VFVBaEwKGt1-KuuRoWgMCjlcaTrb4dEhi0ARJjwusAAAH0P4BiTdLxqfwAAAAUDanceJIVwAANzdbNo5YAAQ4t_T-VV4ACDlV95m_UwAANXgBTSxYAAA4R95khFGABDU-NKIhX0AIOf_pdsVegAQ3Wd-p619AADbZUXsnV0AMODQRdthawAQ5WKXYiF7AADr5aTjFUcAAOEmIH15dQAA5SUQxc16ABDl29VZXX0AAOUpTjflTwAA5S1DuiV7ABDle-rvUW0AANatJosNawABUCFQAVBCUAAA%3D%3D\n"
     ]
    }
   ],
   "source": [
    "with open(STOCK + \".csv\", \"wt\") as file:\n",
    "    i = 0\n",
    "    q = 'https://mobile.twitter.com/search?q=' + STOCK + \\\n",
    "    '%20from%3A' + NEWSPPR + '%20since%3A' + YEAR + \\\n",
    "    '-01-01%20until%3A'+YEAR+'-12-31&src=typd&lang=en'\n",
    "    file.write(\"tweet|time|page\\n\") #header\n",
    "    while(True): #loop para extraer todas las páginas \n",
    "        print(\"Loop %d in URL %s\"%(i,q))\n",
    "        try:\n",
    "            response = requests.get(q)\n",
    "        except:\n",
    "            raise Exception(\"Error al obtener página de resultados.\")\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(\"Error (!= 200) al obtener página de resultados.\")\n",
    "        soup = BeautifulSoup(response.text, 'lxml') #abre la primera página de búsqueda de twitter\n",
    "        extract_tweets(soup, file, i)\n",
    "        \n",
    "        with open(\"%s_%d.html\"%(STOCK,i), 'w') as html:\n",
    "            html.write(response.text)\n",
    "        \n",
    "        nx = soup.find(\"a\", text=\" Load older Tweets \")\n",
    "        if nx != None and nx.has_attr('href'):\n",
    "            q = \"https://mobile.twitter.com\" + nx.get_attribute_list('href')[0]\n",
    "        else:\n",
    "            break\n",
    "        i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next = soup.find(\"a\", text=\" Load older Tweets \")\n",
    "if next.has_attr('href'):\n",
    "    url = next.get_attribute_list('href')\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "s = \"thGAVUV0VFVBYBFoDAo5XGk62-HRIYtAESY8LrAAAB9D-AYk3S8an8AAAAFA2p3HiSFcAADc3WzaOWAAEOf_pdsVegAQ5VfeZv1MAADV4AU0sWAAAOEfeZIRRgAQ1PjSiIV9ACDi39P5VXgAIN1nfqetfQAA22VF7J1dADDg0EXbYWsAEOvlpOMVRwAA5WKXYiF7AADhJiB9eXUAAOUlEMXNegAQ5dvVWV19AADlKU435U8AAOUtQ7olewAQ5Xvq71FtAADWrSaLDWsAAVAhUAFQAlAAA%3D\"\n",
    "s_ = urllib.parse.unquote(s)\n",
    "s_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "base64.b64decode(\"aG9sYSBuacOxb3MK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
