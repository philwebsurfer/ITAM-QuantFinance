{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final\n",
    "\n",
    "_Jorge III Altamirano Astorga - 175904_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs4\n",
    "import requests\n",
    "import sys\n",
    "from dateutil import parser #esta lib es más útil que la de Python para interpretar fechas parciales, como las de Twitter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://mobile.twitter.com/search?q=bimbo%20from%3Aelfinanciero_mx%20since%3A2018-01-01%20until%3A2018-12-31&src=typd&lang=en'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWSPPR=\"elfinanciero_mx\"\n",
    "STOCK=\"bimbo\"\n",
    "YEAR=\"2018\"\n",
    "q = 'https://mobile.twitter.com/search?q=' + STOCK + \\\n",
    "      '%20from%3A' + NEWSPPR + \\\n",
    "      '%20since%3A'+YEAR+'-01-01%20until%3A'+YEAR+'-12-31&src=typd&lang=en'\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweets(soup, file, i, year):\n",
    "    tweets = soup.find_all(\"table\", attrs={\"class\": \"tweet\"})\n",
    "    # soup.find_all(\"div\", attrs={\"class\": \"tweet-text\"})\n",
    "    # tweet = tweets[0]\n",
    "    for tweet in tweets:\n",
    "        tweet_text = tweet.find_all('div', attrs={'class': 'tweet-text'})\n",
    "        tweet_date = tweet.find_all(\"td\", attrs={'class': 'timestamp'})\n",
    "        for text in tweet_text:\n",
    "            if type(text) == bs4.element.Tag:\n",
    "                txt = re.sub(\"(eleconomista\\.com\\.mx|pic\\.twitter\\.com|bit\\.ly|bitly\\.com)/[^ ]*\", \" \", text.text).strip()\n",
    "                txt = re.sub(\"(\\||\\n)\", \" \", txt)\n",
    "                file.write(txt + \"|\")\n",
    "        for date in tweet_date:\n",
    "            if type(date) == bs4.element.Tag:\n",
    "                date = date.text.strip() \n",
    "                date = re.sub(year[-2:] + \"$\", \"\", date)\n",
    "                file.write(str(parser.parse(date + \" \" + year) )  + \"|%s\"%i + \"\\n\")\n",
    "                \n",
    "# get_tweets(year=\"2019\", filename=\"bmv.eleconomista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(query=\"bolsa OR IPC OR BMV\", newspaper=\"elfinanciero_mx\", year=\"2018\", filename=\"file\"):\n",
    "    q = 'https://mobile.twitter.com/search?q=' + query + \\\n",
    "          '%20from%3A' + newspaper + \\\n",
    "          '%20since%3A'+year+'-01-01%20until%3A'+year+'-12-31&src=typd&lang=en'\n",
    "\n",
    "    with open(\"%s.%s.csv\"%(filename,year), \"wt\") as file:\n",
    "        i = 0\n",
    "        q = 'https://mobile.twitter.com/search?q=' + query + \\\n",
    "        '%20from%3A' + newspaper + '%20since%3A' + year + \\\n",
    "        '-01-01%20until%3A' + year +'-12-31&src=typd&lang=en'\n",
    "        file.write(\"tweet|time|page\\n\") #header\n",
    "        while(True): #loop para extraer todas las páginas \n",
    "            print(\"  Downloading page %d...\"%(i+1))\n",
    "            try:\n",
    "                response = requests.get(q)\n",
    "            except:\n",
    "                raise Exception(\"Error al obtener página de resultados.\")\n",
    "            if response.status_code != 200:\n",
    "                raise Exception(\"Error (!= 200) al obtener página de resultados.\")\n",
    "            soup = BeautifulSoup(response.text, 'lxml') #abre la primera página de búsqueda de twitter\n",
    "            extract_tweets(soup, file, i, year)\n",
    "\n",
    "            #with open(\"%s_%d.html\"%(query,i), 'w') as html:\n",
    "            #    html.write(response.text)\n",
    "\n",
    "            nx = soup.find(\"a\", text=\" Load older Tweets \")\n",
    "            if nx != None and nx.has_attr('href'):\n",
    "                q = \"https://mobile.twitter.com\" + nx.get_attribute_list('href')[0]\n",
    "            else:\n",
    "                break\n",
    "            i += 1\n",
    "    print(\"  Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading year 2017 from @elfinanciero_mx\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Downloading page 5...\n",
      "Downloading page 6...\n",
      "Downloading page 7...\n",
      "Downloading page 8...\n",
      "Downloading page 9...\n",
      "Downloading page 10...\n",
      "Downloading page 11...\n",
      "Downloading page 12...\n",
      "Downloading page 13...\n",
      "Downloading page 14...\n",
      "Downloading page 15...\n",
      "Downloading page 16...\n",
      "Downloading page 17...\n",
      "Done!\n",
      "Downloading year 2017 from @eleconomista\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Downloading page 5...\n",
      "Downloading page 6...\n",
      "Downloading page 7...\n",
      "Downloading page 8...\n",
      "Done!\n",
      "Downloading year 2018 from @elfinanciero_mx\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Downloading page 5...\n",
      "Downloading page 6...\n",
      "Downloading page 7...\n",
      "Downloading page 8...\n",
      "Downloading page 9...\n",
      "Downloading page 10...\n",
      "Done!\n",
      "Downloading year 2018 from @eleconomista\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Downloading page 5...\n",
      "Downloading page 6...\n",
      "Downloading page 7...\n",
      "Downloading page 8...\n",
      "Downloading page 9...\n",
      "Downloading page 10...\n",
      "Downloading page 11...\n",
      "Done!\n",
      "Downloading year 2019 from @elfinanciero_mx\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Downloading page 5...\n",
      "Done!\n",
      "Downloading year 2019 from @eleconomista\n",
      "Downloading page 1...\n",
      "Downloading page 2...\n",
      "Downloading page 3...\n",
      "Downloading page 4...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for yr in [\"2017\", \"2018\", \"2019\"]:\n",
    "    for source in [\"elfinanciero_mx\", \"eleconomista\"]:\n",
    "        print(\"Downloading year %s from @%s\"%(yr,source))\n",
    "        get_tweets(query=\"bolsa OR IPC OR BMV\", newspaper=source, year=yr, filename=\"bmv.%s\"%source)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
